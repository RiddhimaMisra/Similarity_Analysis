{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e42124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer  # For Lemmetization of words\n",
    "from nltk.corpus import stopwords  # Load list of stopwords\n",
    "from nltk import word_tokenize # Convert paragraph in tokens\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from gensim.models import word2vec # For represent words in vectors\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4698534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text_data :  (3000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player burn-out worries robinson england coach...   \n",
       "3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  \n",
       "3  redford s vision of sundance despite sporting ...  \n",
       "4  mauresmo opens with victory in la amelie maure...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read given data-set using pandas\n",
    "text_data = pd.read_csv(\"DataNeuron_Text_Similarity.csv\")\n",
    "print(\"Shape of text_data : \", text_data.shape)\n",
    "text_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8828f6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text1    0\n",
       "text2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if text data have any null values\n",
    "text_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa80d4c",
   "metadata": {},
   "source": [
    "Preprocessing of text1 & text2\n",
    "Convert phrases like won't to will not using function decontracted() below\n",
    "Remove Stopwords.\n",
    "Remove any special symbols and lower case all words\n",
    "lemmatizing words using WordNetLemmatizer define in function word_tokenizer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9a183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405ed6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [11:23<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "\n",
    "preprocessed_text1 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "\n",
    "for sentance in tqdm(text_data['text1'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text1.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6444505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text1 in text_data\n",
    "\n",
    "text_data['text1'] = preprocessed_text1\n",
    "text_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1484dda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [11:18<00:00,  4.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_text2 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(text_data['text2'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "   \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text2.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e5854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double glasgow britain jason gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure lack public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted wintry premiere hollywood star t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double glasgow britain jason gar...  \n",
       "1  amnesty chief laments war failure lack public ...  \n",
       "2  hanks greeted wintry premiere hollywood star t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text2 in text_data\n",
    "\n",
    "text_data['text2'] = preprocessed_text2\n",
    "\n",
    "text_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1064c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenizer(text):\n",
    "            #tokenizes and stems the text\n",
    "            tokens = word_tokenize(text)\n",
    "            lemmatizer = WordNetLemmatizer() \n",
    "            tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "            return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d175824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre_trained Google News Vectors after download file\n",
    "\n",
    "wordmodelfile= \"https://drive.google.com/file/d/1mCO_HK5Z9LmfyiUgA0ma673L5iE1d4ld/view?usp=sharing\"\n",
    "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(wordmodelfile, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "993917b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code check if word in text1 & text2 present in our google news vectors vocabalry.\n",
    "# if not it removes that word and if present it compares similarity score between text1 and text2 words\n",
    "\n",
    "\n",
    "similarity = [] # List to store similarity scores\n",
    "\n",
    "\n",
    "for ind in text_data.index:\n",
    "    s1 = text_data['text1'][ind]\n",
    "    s2 = text_data['text2'][ind]\n",
    "    \n",
    "    \n",
    "    if s1 == s2:\n",
    "        similarity.append(1.0) # 1 means highly similar\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        s1words = word_tokenizer(s1)\n",
    "        s2words = word_tokenizer(s2)\n",
    "        \n",
    "        \n",
    "        vocab = wordmodel.key_to_index # The vocabulary considered in the word embeddings\n",
    "        \n",
    "        \n",
    "        if len(s1words and s2words) == 0:\n",
    "            similarity.append(0.0) # 0 means highly dissimilar\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            for word in s1words.copy(): # Remove sentence words not found in the vocab\n",
    "                if word not in vocab:\n",
    "                    s1words.remove(word)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            for word in s2words.copy(): # Remove sentence words not found in the vocab\n",
    "                if word not in vocab:\n",
    "                    s2words.remove(word)\n",
    "                    \n",
    "                    \n",
    "                            \n",
    "            similarity.append(wordmodel.n_similarity(s1words, s2words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcbe44bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.685436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.633329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.717490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID  Similarity_score\n",
       "0          0          0.685436\n",
       "1          1          0.633329\n",
       "2          2          0.717490"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Unique_ID and similarity\n",
    "\n",
    "final_score = pd.DataFrame({'Unique_ID':text_data.index,\n",
    "                     'Similarity_score':similarity})\n",
    "final_score.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b891fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DF as CSV file \n",
    "\n",
    "final_score.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c64ad87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.24.1)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (1.4.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (12.0.0)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (3.1.31)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: toml<2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: requests<3,>=2.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.6.3)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (0.20.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (1.21.5)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.25.2)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.4.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.11.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3->streamlit) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.7.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging<24,>=14.1->streamlit) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3,>=0.25->streamlit) (2021.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2->streamlit) (1.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.4->streamlit) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.4->streamlit) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.4->streamlit) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich<14,>=10.11.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich<14,>=10.11.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit) (2022.7)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from validators<1,>=0.2->streamlit) (5.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee1adf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09184459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 18:06:32.372 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.lower().split())\n",
    "    set2 = set(str2.lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1) + len(set2) - intersection\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Streamlit UI\n",
    "st.title('Text Similarity App')\n",
    "\n",
    "text1 = st.text_input('Enter text 1:')\n",
    "text2 = st.text_input('Enter text 2:')\n",
    "\n",
    "if st.button('Get Similarity Score'):\n",
    "    similarity_score = jaccard_similarity(text1, text2)\n",
    "    st.write('Similarity Score:', similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c36fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
